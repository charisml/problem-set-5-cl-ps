---
title: "Untitled"
format: html
---


## Links and Titles Final
```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://oig.hhs.gov/fraud/enforcement/' 
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')

#print(response)
#print(soup)

main_nochildren = soup.find_all(lambda t: t.name == 'main' and not
t.find_all())

# Find all <h2> tags within <main>
h2_tags = soup.find_all('h2')

# Extract links from <a> tags within each <h2>
links = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links.append(a_tag['href'])

# Print the extracted links
print(links)

# Extracting titles of offences corresponding to each link
links_text = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links_text.append(a_tag.text)

print(links_text)

# Extracting Dates
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <span> tags within each <div> inside <header>
span_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        span_tag = div.find('span')
        if span_tag:
            span_texts.append(span_tag.text.strip())

# Print the extracted text
for text in span_texts:
    print(text)

filtered_texts = span_texts[4:] # Print the filtered list for text in filtered_texts: print(text)

print(filtered_texts)

# Filtering for Categories
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <li> tags within each <ul> inside <div> within <header>
li_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            for li in li_tags:
                li_texts.append(li.text.strip())

# Assuming you have a list called `li_texts`
# Get the last 20 elements
last_20_texts = li_texts[-20:]

print(last_20_texts)

# Create a DataFrame from the lists
df = pd.DataFrame({
    'Title': links_text,
    'Date': filtered_texts,
    'Category': last_20_texts,
    'Link': links
})

# Print the DataFrame
df.head(10)
```

## 2.

```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://oig.hhs.gov/fraud/enforcement/' 
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')


main_nochildren = soup.find_all(lambda t: t.name == 'main' and not
t.find_all())

# Find all <h2> tags within <main>
h2_tags = soup.find_all('h2')

# Extract links from <a> tags within each <h2>
links = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links.append(a_tag['href'])

# Extracting titles of offences corresponding to each link
links_text = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links_text.append(a_tag.text)

# Extracting Dates
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <span> tags within each <div> inside <header>
span_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        span_tag = div.find('span')
        if span_tag:
            span_texts.append(span_tag.text.strip())

filtered_texts = span_texts[4:] # Print the filtered list for text in filtered_texts: print(text)


# Filtering for Categories
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <li> tags within each <ul> inside <div> within <header>
li_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            for li in li_tags:
                li_texts.append(li.text.strip())

# Assuming you have a list called `li_texts`
# Get the last 20 elements
last_20_texts = li_texts[-20:]

# Create a DataFrame from the lists
df = pd.DataFrame({
    'Title': links_text,
    'Date': filtered_texts,
    'Category': last_20_texts,
    'Link': links
})

# Print the DataFrame
df.head(10)

base_url = 'https://oig.hhs.gov'


# Function to extract the enforcement agency from each link
def get_enforcement_agency(relative_url):
    full_url = base_url + relative_url
    response = requests.get(full_url)
    soup = BeautifulSoup(response.content, 'lxml')
    
    # Find the enforcement agency in the second <li> within <ul> inside <div>
    div_tags = soup.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            if len(li_tags) >= 1:
                span_tag = li_tags[1].find('span')  # Second <li> is at index 1
                if span_tag:
                    agency_name = span_tag.text
                    return agency_name
    return None

# Apply the function to each link and create a new column in the DataFrame
df['Enforcement Agency'] = df['Link'].apply(get_enforcement_agency)

# Print the updated DataFrame
# This extracts all text from the second <li> tag

df
```


```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://oig.hhs.gov/fraud/enforcement/' 
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')


main_nochildren = soup.find_all(lambda t: t.name == 'main' and not
t.find_all())

# Find all <h2> tags within <main>
h2_tags = soup.find_all('h2')

# Extract links from <a> tags within each <h2>
links = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links.append(a_tag['href'])

# Extracting titles of offences corresponding to each link
links_text = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links_text.append(a_tag.text)

# Extracting Dates
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <span> tags within each <div> inside <header>
span_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        span_tag = div.find('span')
        if span_tag:
            span_texts.append(span_tag.text.strip())

filtered_texts = span_texts[4:] # Print the filtered list for text in filtered_texts: print(text)


# Filtering for Categories
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <li> tags within each <ul> inside <div> within <header>
li_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            for li in li_tags:
                li_texts.append(li.text.strip())

# Assuming you have a list called `li_texts`
# Get the last 20 elements
last_20_texts = li_texts[-20:]

# Create a DataFrame from the lists
df = pd.DataFrame({
    'Title': links_text,
    'Date': filtered_texts,
    'Category': last_20_texts,
    'Link': links
})

# Print the DataFrame
df.head(10)

base_url = 'https://oig.hhs.gov'


# Function to extract the enforcement agency from each link
def get_enforcement_agency(relative_url):
    full_url = base_url + relative_url
    response = requests.get(full_url)
    soup = BeautifulSoup(response.content, 'lxml')
    div_tags = soup.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            if len(li_tags) >= 1:
                agency_name = li_tags.find('agency')
                return agency_name  # Second <li> is at index 1
    return None

# Apply the function to each link and create a new column in the DataFrame
df['Enforcement Agency'] = df['Link'].apply(get_enforcement_agency)

# Print the updated DataFrame
# This extracts all text from the second <li> tag

df
```