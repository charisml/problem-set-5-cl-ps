---
title: "Untitled"
format: html
---


## 1.
```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://oig.hhs.gov/fraud/enforcement/' 
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')

#print(response)
#print(soup)

main_nochildren = soup.find_all(lambda t: t.name == 'main' and not
t.find_all())

# Find all <h2> tags within <main>
h2_tags = soup.find_all('h2')

# Extract links from <a> tags within each <h2>
links = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links.append(a_tag['href'])

# Print the extracted links
print(links)

# Extracting titles of offences corresponding to each link
links_text = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links_text.append(a_tag.text)

print(links_text)

# Extracting Dates
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <span> tags within each <div> inside <header>
span_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        span_tag = div.find('span')
        if span_tag:
            span_texts.append(span_tag.text.strip())

# Print the extracted text
for text in span_texts:
    print(text)

filtered_texts = span_texts[4:] # Print the filtered list for text in filtered_texts: print(text)

print(filtered_texts)

# Filtering for Categories
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <li> tags within each <ul> inside <div> within <header>
li_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            for li in li_tags:
                li_texts.append(li.text.strip())

# Assuming you have a list called `li_texts`
# Get the last 20 elements
last_20_texts = li_texts[-20:]

print(last_20_texts)

# Create a DataFrame from the lists
df = pd.DataFrame({
    'Title': links_text,
    'Date': filtered_texts,
    'Category': last_20_texts,
    'Link': links
})

# Print the DataFrame
df.head(10)
```

## 2.

```{python}
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = 'https://oig.hhs.gov/fraud/enforcement/' 
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')


main_nochildren = soup.find_all(lambda t: t.name == 'main' and not
t.find_all())

# Find all <h2> tags within <main>
h2_tags = soup.find_all('h2')

# Extract links from <a> tags within each <h2>
links = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links.append(a_tag['href'])

# Extracting titles of offences corresponding to each link
links_text = []
for h2 in h2_tags:
    a_tag = h2.find('a', href=True)
    if a_tag:
        links_text.append(a_tag.text)

# Extracting Dates
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <span> tags within each <div> inside <header>
span_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        span_tag = div.find('span')
        if span_tag:
            span_texts.append(span_tag.text.strip())

filtered_texts = span_texts[4:] # Print the filtered list for text in filtered_texts: print(text)


# Filtering for Categories
# Find all <header> elements
header_tags = soup.find_all('header')

# Extract text from <li> tags within each <ul> inside <div> within <header>
li_texts = []
for header in header_tags:
    div_tags = header.find_all('div')
    for div in div_tags:
        ul_tags = div.find_all('ul')
        for ul in ul_tags:
            li_tags = ul.find_all('li')
            for li in li_tags:
                li_texts.append(li.text.strip())

# Assuming you have a list called `li_texts`
# Get the last 20 elements
last_20_texts = li_texts[-20:]

# Create a DataFrame from the lists
df = pd.DataFrame({
    'Title': links_text,
    'Date': filtered_texts,
    'Category': last_20_texts,
    'Link': links
})

base_url = 'https://oig.hhs.gov'

# This extracts all text from the second <li> tag
agency_info_list = [] # Add your list of URLs here
for i in df['Link']:
    # Specify the URL
    url = base_url + i
    
    # Fetch the page content
    response = requests.get(url)
    response.raise_for_status()
    
    # Parse the HTML content with Beautiful Soup
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Use the CSS selector path to find the element
    agency_info = soup.select_one('#main-content > div > div:nth-child(2) > article > div > ul > li:nth-child(2)')
    
    # Check if the element is found and print its text
    if agency_info: 
        agency_info_list.append(agency_info.get_text(strip=True)) 
    else: 
        agency_info_list.append("Agency information not found.")
    
# Taking out word "Agency:"
cleaned_agency_info_list = [info.replace("Agency:", "").strip() for info in agency_info_list] 

# Appending 'Enforcement Agency' column to df
df['Enforcement Agency'] = cleaned_agency_info_list 
df
```
